{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score,brier_score_loss\n",
    "import numpy as np\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up data and task name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=''\n",
    "task = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-fold corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path)\n",
    "data['year'] = data.study_entry.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data):\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def train_iter(train, test):\n",
    "    time_col = 'time2event'\n",
    "    label_col = 'label'\n",
    "    formular = \"age+gen_ethnicity+imd2015_5+systolic+systolic_std+BMI+hdl+smoke+chd_history+diabetes+rheumatoid_arthritis+atrial_fibrillation+ckd+migraine+lupus_erythematosus+mental_ill+hiv_aids+ED+antihtn+antipsychotic+corticosteroid\"\n",
    "    t0 = 12*5\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train, duration_col=time_col, event_col=label_col, formula=formular)\n",
    "\n",
    "    auroc, auprc = evaluate_auroc_auprc(cph, test, t0=t0)\n",
    "    \n",
    "    return auroc, auprc\n",
    "\n",
    "def evaluate_auroc_auprc(model, data, t0=12*5):\n",
    "    def ccl(p):\n",
    "        return np.log(-np.log(1 - p))\n",
    "\n",
    "    T = model.duration_col\n",
    "    E = model.event_col\n",
    "    t0 = t0\n",
    "\n",
    "    predictions_at_t0 = np.clip(1 - model.predict_survival_function(data, times=[t0]).T.squeeze(), 1e-10, 1 - 1e-10)\n",
    "    \n",
    "    auprc = average_precision_score(data[E].values, predictions_at_t0)\n",
    "    auroc = roc_auc_score(data[E].values, predictions_at_t0)\n",
    "    \n",
    "    return auroc, auprc\n",
    "\n",
    "def prediction(model, data, t0=12*5):\n",
    "    def ccl(p):\n",
    "        return np.log(-np.log(1 - p))\n",
    "\n",
    "    T = model.duration_col\n",
    "    E = model.event_col\n",
    "    t0 = t0\n",
    "\n",
    "    predictions_at_t0 = np.clip(1 - model.predict_survival_function(data, times=[t0]).T.squeeze(), 1e-10, 1 - 1e-10)\n",
    "    \n",
    "    patid = data.patid.values\n",
    "    \n",
    "    return patid, data[E].values, predictions_at_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_list = []\n",
    "roc_list = []\n",
    "for i in range(5):\n",
    "    train, test= generate_data(data)\n",
    "    roc, prc = train_iter(train, test)\n",
    "    print('iter {}, auroc: {}, auprc: {}'.format(i, roc, prc))\n",
    "    prc_list.append(prc)\n",
    "    roc_list.append(roc)\n",
    "\n",
    "print('summary roc mean: {} 95%CI: {}'.format(np.mean(roc_list), 1.96*np.std(roc_list)))\n",
    "print('summary prc mean: {} 95%CI: {}'.format(np.mean(prc_list), 1.96*np.std(prc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross region validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year\n",
    "def generate_data(data, region):\n",
    "    train, test = data[data['region'].isin(region[0])], data[data['region'].isin(region[1])]\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    return train, test\n",
    "\n",
    "def train_iter(train, test):\n",
    "    time_col = 'time2event'\n",
    "    label_col = 'label'\n",
    "    \n",
    "    #\n",
    "    formular = \"\"\n",
    "    \n",
    "    t0 = 12*5\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train, duration_col=time_col, event_col=label_col, formula=formular)\n",
    "\n",
    "    auroc, auprc = evaluate_auroc_auprc(cph, test, t0=t0)\n",
    "    \n",
    "    return auroc, auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [['4','5','6','7','8','9','10'], ['1','2','3']]\n",
    "\n",
    "prc_list = []\n",
    "roc_list = []\n",
    "for i in range(5):\n",
    "    train, test = generate_data(data, region)\n",
    "    roc, prc = train_iter(train, test)\n",
    "\n",
    "    prc_list.append(prc)\n",
    "    roc_list.append(roc)\n",
    "\n",
    "print('summary roc mean: {} 95%CI: {}'.format(np.mean(roc_list), 1.96*np.std(roc_list)))\n",
    "print('summary prc mean: {} 95%CI: {}'.format(np.mean(prc_list), 1.96*np.std(prc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD validation year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path)\n",
    "data['year'] = data.study_entry.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data(data, year=2000):\n",
    "    train = data[data['year']< year]\n",
    "    train = train.reset_index(drop=True)\n",
    "    return train\n",
    "\n",
    "def train_model(train):\n",
    "    time_col = 'time2event'\n",
    "    label_col = 'label'\n",
    "    \n",
    "    # set up formular to train CPH model\n",
    "    formular = \"\"\n",
    "    t0 = 12*5\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train, duration_col=time_col, event_col=label_col, formula=formular)\n",
    "    return cph\n",
    "\n",
    "def generate_test_data(data, year=(2000, 2001)):\n",
    "    test = data[(data['year']>= year[0])&(data['year']<year[1])]\n",
    "    test = test.reset_index(drop=True)\n",
    "    return test\n",
    "\n",
    "def eval_model(test, clf, t0=12*5):\n",
    "    auroc, auprc = evaluate_auroc_auprc(clf, test, t0=t0)\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = [(1999, 2000), (2000, 2001), (2001, 2002), (2002, 2003), (2003, 2004), (2004, 2005), \n",
    "        (2005, 2006), (2006, 2007), (2007, 2008), (2008, 2009), (2009, 2010)]\n",
    "\n",
    "train = generate_train_data(data, year=2000)\n",
    "clf = train_model(train)\n",
    "\n",
    "for each in year:\n",
    "    test = generate_test_data(data, year=each)\n",
    "    roc= eval_model(test, clf)\n",
    "    print('{}-{} ROC: {}'.format(each[0], each[1], roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [(2001, (2006,2007)), (2002, (2007,2008)), (2003, (2008,2009)), (2004, (2009,2010))]\n",
    "\n",
    "\n",
    "for each in year:\n",
    "    train= generate_train_data(data, year=each[0])\n",
    "    clf = train_model(train)\n",
    "    \n",
    "    test= generate_test_data(data, year=each[1])\n",
    "    roc = eval_model(test, clf)\n",
    "    print('{},{}-{} ROC: {}'.format(each[0],each[1][0], each[1][1], roc,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_parquet(path)\n",
    "    \n",
    "year = [(2000, 2001), (2001, 2002), (2002, 2003), (2003, 2004), (2004, 2005), \n",
    "        (2005, 2006), (2006, 2007), (2007, 2008), (2008, 2009), (2009, 2010)]\n",
    "\n",
    "train= generate_train_data(data, year=2000)\n",
    "clf = train_model(train)\n",
    "plt.figure(figsize=(2, 2), dpi=300)\n",
    "for each in year:\n",
    "    test = generate_test_data(data, year=each)\n",
    "    _, label, predict = prediction( clf, test)\n",
    "    \n",
    "    observe, estimate = calibration_curve(label, predict, n_bins=10)\n",
    "    calibration_df = pd.DataFrame({'Observed risk': observe, 'Estimated risk': estimate})\n",
    "    sns.regplot(x=\"Estimated risk\", y=\"Observed risk\", data=calibration_df, order=2, ci=None, label='{}-{}'.format(each[0], each[1])  , marker='')\n",
    "x= np.linspace(0,1,10)\n",
    "plt.plot(x,x,label='reference',color='black')\n",
    "plt.title(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_parquet(path)\n",
    "\n",
    "name_map = {\n",
    "    '2000': \"A\",\n",
    "    '2001': \"B\",\n",
    "    '2002': \"C\",\n",
    "    '2003': \"D\", \n",
    "    '2004': \"E\"\n",
    "}\n",
    "\n",
    "\n",
    "year = [(2000, (2005,2006)), (2001, (2006,2007)), (2002, (2007,2008)), (2003, (2008,2009)), (2004, (2009,2010))]\n",
    "\n",
    "plt.figure(figsize=(2, 2), dpi=300)\n",
    "for each in year:\n",
    "    train = generate_train_data(data, year=each[0])\n",
    "    clf = train_model(train)\n",
    "    test = generate_test_data(data, year=each[1])\n",
    "    _, label, predict = prediction(clf, test)\n",
    "    \n",
    "    observe, estimate = calibration_curve(label, predict, n_bins=10)\n",
    "    calibration_df = pd.DataFrame({'Observed risk': observe, 'Estimated risk': estimate})\n",
    "    sns.regplot(x=\"Estimated risk\", y=\"Observed risk\", data=calibration_df, order=2, ci=None, label=name_map.get(each[0]) , marker='')\n",
    "x= np.linspace(0,1,10)\n",
    "plt.plot(x,x,label='reference',color='black')\n",
    "plt.title(task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
